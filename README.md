# ğŸš€ Git2Gold: Incremental Lakehouse Pipeline with PySpark

This project showcases an **end-to-end Data Engineering pipeline** that ingests raw data from a **GitHub-hosted source**, processes it incrementally through **Bronze â†’ Silver â†’ Gold** layers on **Azure Data Lake Storage (ADLS)** using **PySpark**, and builds a **star schema** in the Gold layer for downstream analytics.

---

## ğŸ“ Project Structure
â”œâ”€â”€ part_1(github_to_sql_db)
â”‚ â””â”€â”€ Ingest data from GitHub and load to Azure SQL DB
â”‚
â”œâ”€â”€ part_2(incremental_data_pipeline_sqldb_to_bronze)
â”‚ â””â”€â”€ Read from SQL DB, apply incremental filter, write to ADLS (Bronze)
â”‚
â”œâ”€â”€ part_3(all_databricks_notebooks)
â”‚ â””â”€â”€ PySpark transformation scripts for Silver & Gold layer
â”‚
â”œâ”€â”€ part_4(final_workflow)
â”‚ â””â”€â”€ Workflow integration + surrogate key handling + Delta Lake save

## âš™ï¸ Technologies & Tools

- **Azure Data Lake Storage (Gen2)**
- **Azure SQL Database**
- **Databricks (PySpark notebooks)**
- **Delta Lake**
- **GitHub REST API (source)**
- **Star Schema Modeling (Dim/Fact)**

---

## ğŸ” Incremental Load Logic

- Controlled by `incremental_flag` using `dbutils.widgets`.
- If `incremental_flag == 0`, full load is triggered.
- If `incremental_flag == 1`, only data with a newer surrogate key is loaded.
- Surrogate key is managed as `Dim_model_key` in the Gold layer using SQL logic + PySpark.

---

## ğŸ§  Key Features

- ğŸ”— **Automated Ingestion** from GitHub to Azure via REST API
- ğŸª„ **Incremental Pipeline** with config-driven loads
- ğŸ§¼ **PySpark Transformations** (Bronze â†’ Silver)
- ğŸ† **Dimensional Modeling** with star schema in the Gold layer
- ğŸ’¾ **Delta Format Tables** optimized for querying

---

## ğŸ“Œ How to Use

1. Set up your Azure resources: ADLS, SQL DB, Databricks.
2. Connect your GitHub source in `part_1`.
3. Run scripts in order from part_1 to part_4.
4. Modify `dbutils.widgets.get('incremental_flag')` to control the load behavior.
5. Final outputs are saved as Delta tables in the Gold layer.

---

## ğŸ“‚ Sample Data Files

The following zipped project files were used to support pipeline execution:
- `project_incre.zip`
- `incre_data_pipeline_support_live.zip`
- `source_prep_support_live.zip`

*(now organized under relevant folders for easier understanding)*

---

## ğŸ¤ Contributing

Pull requests and feedback are welcome! Feel free to fork the repo and submit changes.

---

## ğŸ“œ License

This project is open-source under the [MIT License](LICENSE).

---

## ğŸ‘©â€ğŸ’» Author

**Ravina Babal**  
_Data Engineer | Azure + PySpark Enthusiast_  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/ravina-babal-7195821b1)
